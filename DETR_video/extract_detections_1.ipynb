{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdSaGm9reLjV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.optimize import linear_sum_assignment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/detr:main', 'detr_resnet50', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7hLLvEeRLt",
        "outputId": "80daf54e-4f72-4a28-fde1-3253f6f701fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 106MB/s]\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n",
            "100%|██████████| 159M/159M [00:01<00:00, 105MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "sZnUeiE0_na0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sim_VGG16_net:\n",
        "    def __init__(self):\n",
        "        # Carica il modello VGG16 pre-addestrato\n",
        "        self.base_model = VGG16(weights='imagenet', include_top=True)\n",
        "        # Estrai l'output dello strato prima dell'ultimo strato completamente connesso\n",
        "        self.model = Model(inputs=self.base_model.input, outputs=self.base_model.get_layer('fc2').output)\n",
        "\n",
        "    # Funzione per caricare e pre-processare un'immagine\n",
        "    def load_and_preprocess_image(self, frame):\n",
        "        # img = image.load_img(image_path, target_size=(224, 224))\n",
        "        # VGG accetta in input immagini 224x224\n",
        "        frame = frame.convert('RGB')\n",
        "        img_resized = frame.resize((224, 224))\n",
        "        img_array = image.img_to_array(img_resized)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "        return img_array\n",
        "\n",
        "    # Funzione per estrarre le features da un'immagine\n",
        "    def extract_features_nb(self, frame):\n",
        "        img = self.load_and_preprocess_image(frame)\n",
        "        features = self.model.predict(img)\n",
        "        return features.flatten()\n",
        "\n",
        "    # Funzione per estrarre le features da un'immagine\n",
        "    def extract_features(self, frame, bbox):\n",
        "        # Definisci il bounding box per il crop\n",
        "        # (left, upper): The coordinates of the top-left corner of the bounding box.\n",
        "        # (right, lower): The coordinates of the bottom-right corner of the bounding box.\n",
        "        x1,y1,x2,y2 = bbox  # (left, upper, right, lower)\n",
        "        x1 = int(x1)\n",
        "        y1 = int(y1)\n",
        "        x2 = int(x2)\n",
        "        y2 = int(y2)\n",
        "        sub_box = (x1,y1,x2,y2)\n",
        "        subbox = frame.crop(sub_box)\n",
        "        img = self.load_and_preprocess_image(subbox)\n",
        "        # per togliere il verbose model.predict(x,verbose=0)\n",
        "        # features = self.model.predict(img)\n",
        "        features = self.model.predict(img,verbose=0)\n",
        "        return features.flatten()\n",
        "\n",
        "    # Funzione per calcolare la similarità tra due immagini basata sulla distanza coseno delle features\n",
        "    def calculate_similarity(self, frame1, frame2):\n",
        "        features1 = self.extract_features(frame1)\n",
        "        features2 = self.extract_features(frame2)\n",
        "        # Calcola la distanza coseno tra le features\n",
        "        similarity = 1 - cosine(features1, features2)\n",
        "        return similarity\n",
        "\n",
        "    def calculate_similarity_reid(self, frame1, features2):\n",
        "        features1 = self.extract_features(frame1)\n",
        "        similarity = 1 - cosine(features1, features2)\n",
        "        return similarity\n",
        "\n",
        "    def calulate_similarity_features(self,features1, features2):\n",
        "        similarity = 1 - cosine(features1, features2)\n",
        "        return similarity\n"
      ],
      "metadata": {
        "id": "gsR7k4Tz8Mch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = sim_VGG16_net()"
      ],
      "metadata": {
        "id": "gdSOxA-uEFk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db48bb4-3e40-4acc-85b2-813e1279f8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 9s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image_test1 = Image.open('/content/image_test_1.jpg')\n",
        "# image_test2 = Image.open('/content/image_test_2.jpg')"
      ],
      "metadata": {
        "id": "JcDQdHAADrpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_test1"
      ],
      "metadata": {
        "id": "YpDJIwSnHHaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_test2"
      ],
      "metadata": {
        "id": "2g8spo5lHuPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features1 = vgg16.extract_features_nb(image_test1) #nb stands for no bounding boxes\n",
        "# features1.shape"
      ],
      "metadata": {
        "id": "ewXjSbZXEFIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features2 = vgg16.extract_features_nb(image_test2)\n",
        "# features2.shape"
      ],
      "metadata": {
        "id": "A3VuYFoVEjI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.calulate_similarity_features(features1, features2)"
      ],
      "metadata": {
        "id": "wfrE515-ElwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.calulate_similarity_features(features1, features1)"
      ],
      "metadata": {
        "id": "AHaLUx8_Eygh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.calulate_similarity_features(features2, features1)"
      ],
      "metadata": {
        "id": "-93dVy9XE0rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg16.calulate_similarity_features(features2, features2)"
      ],
      "metadata": {
        "id": "gIZ9nNbdE3EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
      ],
      "metadata": {
        "id": "QJOP71jfeWav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = [\n",
        "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
        "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
        "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
        "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "Sg3WvQi3eTjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "\n",
        "    return torch.stack(b, dim=1)\n",
        "\n",
        "'''def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h, _ = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "    return b'''\n",
        "\n",
        "def plot_results(pil_img, prob, boxes):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), COLORS * 100):\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                   fill=False, color=c, linewidth=3))\n",
        "        cl = p.argmax()\n",
        "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
        "        ax.text(xmin, ymin, text, fontsize=15,\n",
        "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "'''def detect(model, im, transform = None, threshold_confidence = 0.7):\n",
        "    if transform is None:\n",
        "        # standard PyTorch mean-std input image normalization\n",
        "        transform = T.Compose([\n",
        "        T.Resize(800),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    img = transform(im).unsqueeze(0)\n",
        "\n",
        "    # demo model only support by default images with aspect ratio between 0.5 and 2\n",
        "    # if you want to use images with an aspect ratio outside this range\n",
        "    # rescale your image so that the maximum size is at most 1333 for best results\n",
        "    assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\n",
        "\n",
        "    # propagate through the model\n",
        "    outputs = model(img)\n",
        "\n",
        "    # keep only predictions with a confidence > threshold_confidence\n",
        "    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
        "    keep = probas.max(-1).values > threshold_confidence\n",
        "\n",
        "    # convert boxes from [0; 1] to image scales\n",
        "    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
        "    return probas[keep], bboxes_scaled'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "630Ah46tYQJM",
        "outputId": "d2d9dd6e-fc76-4622-861a-afd251ce1278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def detect(model, im, transform = None, threshold_confidence = 0.7):\\n    if transform is None:\\n        # standard PyTorch mean-std input image normalization\\n        transform = T.Compose([\\n        T.Resize(800),\\n        T.ToTensor(),\\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n        ])\\n\\n    img = transform(im).unsqueeze(0)\\n\\n    # demo model only support by default images with aspect ratio between 0.5 and 2\\n    # if you want to use images with an aspect ratio outside this range\\n    # rescale your image so that the maximum size is at most 1333 for best results\\n    assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\\n\\n    # propagate through the model\\n    outputs = model(img)\\n\\n    # keep only predictions with a confidence > threshold_confidence\\n    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\\n    keep = probas.max(-1).values > threshold_confidence\\n\\n    # convert boxes from [0; 1] to image scales\\n    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\\n    return probas[keep], bboxes_scaled\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale_bboxes(boxes, size):\n",
        "\n",
        "    img_w, img_h = size\n",
        "\n",
        "    b = box_cxcywh_to_xyxy(boxes)\n",
        "\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "\n",
        "    return b"
      ],
      "metadata": {
        "id": "I5VgzU0GYRJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per rilevare i pedoni (modifica di quella della prof)\n",
        "def detect_pedestrians(threshold_confidence, model, im, transform = None):\n",
        "    if transform is None:\n",
        "\n",
        "        # standard PyTorch mean-std input image normalization\n",
        "        transform = T.Compose([\n",
        "        T.Resize(800),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    img = transform(im).unsqueeze(0)\n",
        "\n",
        "    # demo model only support by default images with aspect ratio between 0.5 and 2\n",
        "    # if you want to use images with an aspect ratio outside this range\n",
        "    # rescale your image so that the maximum size is at most 1333 for best results\n",
        "    assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'\n",
        "\n",
        "    outputs = model(img)\n",
        "\n",
        "    # keep only predictions with a confidence > threshold_confidence\n",
        "    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
        "    max_probas = probas.max(-1).values\n",
        "    keep = probas.max(-1).values > threshold_confidence\n",
        "    labels = probas.argmax(-1)\n",
        "\n",
        "    # Filter by pedestrian\n",
        "    keep = keep & (labels == 1)\n",
        "\n",
        "    # Extract the confidences for the kept boxes\n",
        "    confidences = max_probas[keep].detach().numpy()\n",
        "\n",
        "    # convert boxes from [0; 1] to image scales\n",
        "    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)\n",
        "    return confidences, bboxes_scaled.detach().numpy()"
      ],
      "metadata": {
        "id": "3Tpte26_YURW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conf, bboxes_scaled = detect_pedestrians(model, Image.open('/content/im.jpg'))\n",
        "# print(conf)\n",
        "# print(bboxes_scaled)"
      ],
      "metadata": {
        "id": "xliz5_jBYWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frame_test = Image.open('/content/im.jpg')\n",
        "# features_test = []\n",
        "# for bbox in bboxes_scaled:\n",
        "#     feature = vgg16.extract_features(frame_test, bbox)\n",
        "#     features_test.append(feature)\n",
        "#     print(feature.shape)"
      ],
      "metadata": {
        "id": "rNaX_B07OHfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_frame0 = features_test[2]\n",
        "# feature_frame1 = features_test[4]\n",
        "# vgg16.calulate_similarity_features(feature_frame0, feature_frame1)"
      ],
      "metadata": {
        "id": "W0ABMLNNO7D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tracker:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # Lista di tracker\n",
        "        self.trackers = []\n",
        "\n",
        "        # Contatore per assegnare ID univoci ai pedoni\n",
        "        self.track_counter = 0\n",
        "\n",
        "        # Quanti frame devo aspettare prima che il tracker venga rimosso dall'immagine\n",
        "        self.max_lost_frames = 10\n",
        "\n",
        "        # definisco un vettore di vanishing tracks, che mi servirà poi per determinare\n",
        "        # quelli che sono i track che avevo perso. Rispecchia la struttura di un trackers\n",
        "        # ma è formato da <id> <feature_desc> <lost>\n",
        "        self.vanishing_tracks = []\n",
        "\n",
        "        self.dead_tracks = []\n",
        "\n",
        "    def update_tracker(self, confidences, detections, frame, vgg16, theshold_det_track=1.0, theshold_reid=1.0):\n",
        "\n",
        "        # Se non ci sono tracker, significa che è il primo insieme di rilevamenti, quindi bisogna aggiungere ogni nuovo oggetto tracciato\n",
        "        if not self.trackers:\n",
        "            # print(\"Inizializzazione\")\n",
        "            for (detection,conf) in zip(detections,confidences):\n",
        "                track = {'bbox': detection, 'id': self.track_counter, 'conf':conf, 'lost':0}\n",
        "                self.trackers.append(track)\n",
        "                self.track_counter += 1\n",
        "\n",
        "        # In caso contrario, bisogna gestire i rilevamenti esistenti\n",
        "        else:\n",
        "\n",
        "            # Memorizza i rilevamenti esistenti, ovvero le identità presenti al momento\n",
        "            current_bboxes = [tracker['bbox'] for tracker in self.trackers if tracker['lost'] == 0]\n",
        "            current_frames = [tracker for tracker in self.trackers if tracker['lost'] == 0]\n",
        "\n",
        "            # Calcola la matrice di costo tra le identità giù segnate al frame t-1\n",
        "            # e le nuove detection\n",
        "            cost_matrix = np.zeros((len(current_bboxes), len(detections)))\n",
        "\n",
        "            for tracker_index, tracker in enumerate(current_bboxes):\n",
        "                for detection_index, detection in enumerate(detections):\n",
        "                    cost_matrix[tracker_index, detection_index] = self.compute_cost(tracker, detection)\n",
        "\n",
        "            # max = cost_matrix.max()\n",
        "            max = 1\n",
        "            norm_cost_matrix = cost_matrix / max\n",
        "            row_indices, col_indices = linear_sum_assignment(norm_cost_matrix)\n",
        "\n",
        "            # Crea una lista di coppie con le corrispondenze ottimali\n",
        "            matched_indices = list(zip(row_indices, col_indices))\n",
        "\n",
        "            # Crea dei set di detection e tracker non matchati\n",
        "            unmatched_detections = set(range(len(detections))) - set(col_indices)\n",
        "            unmatched_trackers = set(range(len(current_bboxes))) - set(row_indices)\n",
        "\n",
        "            # Itera su tutte le coppie di indici corrispondenti ottenute dall'algoritmo ungherese.\n",
        "            # Per ogni coppia aggiorna il bounding box e rimposta il contatore di fotogrammi persi a zero perché il rilevamento dell'oggetto continua.\n",
        "            for t_idx, d_idx in matched_indices:\n",
        "                # qui bisogna mettere una soglia sulle assegnazioni corrispondenti,\n",
        "                # se il valore della matrice di costo C[t_idx, d_idx] è maggiore di un certo valore allora assegna\n",
        "                # altrimenti è un lost!\n",
        "                # usare theshold_det_track\n",
        "                # print(norm_cost_matrix[t_idx, d_idx])\n",
        "                # se stanno sotto la soglia allora vanno bene, altrimenti devo scartarli\n",
        "                # sotto perché è un problema di minimo\n",
        "                id_track = current_frames[t_idx]['id']\n",
        "                # print(id_track)\n",
        "                if self.trackers[id_track]['lost'] == 0:\n",
        "                    # questo vale solo per le non lost detections\n",
        "                    if norm_cost_matrix[t_idx, d_idx] <= theshold_det_track:\n",
        "                        # print(f\"matched {id_track} between frames\")\n",
        "                        self.trackers[id_track]['bbox'] = detections[d_idx] # aggiorna la bounding box\n",
        "                        self.trackers[id_track]['conf'] = confidences[d_idx] # aggiorna la confidence\n",
        "                        self.trackers[id_track]['lost'] = 0 # aggiorna il numero di frame persi\n",
        "                        # else:\n",
        "                        #     print(\"Per i track con lost != 0 devo vedere con i vanishing!\")\n",
        "                    else:\n",
        "                        # il valore è inferiore alla soglia richiesta\n",
        "                        # print(\"value above theshold_det_track: discard for matching\")\n",
        "                        # print(norm_cost_matrix[t_idx, d_idx])\n",
        "                        self.trackers[id_track]['lost'] += 1\n",
        "                        bbx = self.trackers[id_track]['bbox']\n",
        "                        feature_lost = vgg16.extract_features(frame,bbx)\n",
        "                        lost_track = {'id':id_track, 'bbox': self.trackers[id_track]['bbox'], 'conf': self.trackers[id_track]['conf'], 'feature': feature_lost}\n",
        "                        self.vanishing_tracks.append(lost_track)\n",
        "\n",
        "            # Aggiungi nuovi rilevamenti che non hanno corrispondenze precedenti alla lista dei tracker\n",
        "            # for d_idx in unmatched_detections:\n",
        "            #     new_track = {'bbox': detections[d_idx], 'id': self.track_counter, 'conf':confidences[d_idx], 'lost':0}\n",
        "            #     self.trackers.append(new_track)\n",
        "            #     self.track_counter += 1\n",
        "            # prima di aggiungere i nuovi rilevamenti devo andare a scandire gli unmatched_detections.\n",
        "            # Cosa devo fare qua:\n",
        "            # 1- prendo i unmatched_detections e i vanishing_tracks\n",
        "            # 2- determino una matrice di costo proprio come fatto prima\n",
        "            # 3- per righe metto i vanishing_tracks, per colonne le unmatched_detections\n",
        "            # 4- estraggo le colonne e le righe dal mio algoritmo\n",
        "            remaining_detection = []\n",
        "            remaining_confidences = []\n",
        "            for d_idx in unmatched_detections:\n",
        "                remaining_detection.append(detections[d_idx])\n",
        "                remaining_confidences.append(confidences[d_idx])\n",
        "            # print(len(remaining_detection))\n",
        "            # print(remaining_detection)\n",
        "            # print(len(unmatched_detections))\n",
        "            # print(unmatched_detections)\n",
        "            if len(self.vanishing_tracks) != 0 and len(unmatched_detections) != 0:\n",
        "                # print(\"Re-identfication pass\")\n",
        "                cost_matrix_reid = np.zeros((len(self.vanishing_tracks), len(unmatched_detections)))\n",
        "                # vedere cosa stampa qua, l'errore si trova qua circa\n",
        "                for v_idx, detection_lost in enumerate(self.vanishing_tracks):\n",
        "                    for d_idx, detection_remain in enumerate(remaining_detection):\n",
        "                        # print(\"breakpoint1\")\n",
        "                        # feature1 corrispondono alle feature della detection non matchata\n",
        "                        feature_1 = vgg16.extract_features(frame,detection_remain)\n",
        "                        # feature2 corrisponde invece alle feature che ho traccate\n",
        "                        # print(\"breakpoint5\")\n",
        "                        feature_2 = detection_lost['feature']\n",
        "                        sim_features = vgg16.calulate_similarity_features(feature_2, feature_1)\n",
        "                        # print(\"breakpoint6\")\n",
        "                        d_features = 1 - sim_features # varia tra 0 e 1\n",
        "                        IoU = self.iou(detection_lost['bbox'], detection_remain)\n",
        "                        d_IoU = 1 - IoU\n",
        "                        cost_matrix_reid[v_idx, d_idx] = 0.6 * d_features + 0.4 * d_IoU\n",
        "                        # print(\"breakpoint2\")\n",
        "\n",
        "                max_reid = cost_matrix_reid.max()\n",
        "                # normalizzo la matrice\n",
        "                # print(f'Max reid: {max_reid}')\n",
        "                # norm_cost_matrix_reid = cost_matrix_reid / max_reid\n",
        "                norm_cost_matrix_reid = cost_matrix_reid\n",
        "\n",
        "                row_indices, col_indices = linear_sum_assignment(norm_cost_matrix_reid)\n",
        "\n",
        "                # Crea una lista di coppie con le corrispondenze ottimali\n",
        "                matched_indices_reid = list(zip(row_indices, col_indices)) # ho matchato le vanishing\n",
        "\n",
        "                vanishing_list_enumerate = []\n",
        "                # vanishing_list_enumerate = enumerate(self.vanishing_tracks)\n",
        "                for t_idx, det in enumerate(self.vanishing_tracks):\n",
        "                    vanishing_list_enumerate.append(det)\n",
        "\n",
        "                # riassegno le matched solo se hanno un valore di soglia opportuno\n",
        "                for t_idx, d_idx in matched_indices_reid:\n",
        "                    feature_1_test = vgg16.extract_features(frame,remaining_detection[d_idx])\n",
        "                    feature_2_test = vanishing_list_enumerate[t_idx]['feature']\n",
        "                    # print(f'Similarità: {vgg16.calulate_similarity_features(feature_1_test,feature_2_test)}')\n",
        "                    bbox = vanishing_list_enumerate[t_idx]['bbox']\n",
        "                    # print(f'IoU sim: {self.iou(bbox,remaining_detection[d_idx])}')\n",
        "                    if norm_cost_matrix_reid[t_idx, d_idx] <= theshold_reid:\n",
        "                        # aggiorno utilizzando l'ID delle vanished che cammina di pari passo con trackers\n",
        "                        # con le remaining_detections\n",
        "                        # print(f\"Effettuata reidentificazione: {vanishing_list_enumerate[t_idx]['id']}\")\n",
        "                        self.trackers[vanishing_list_enumerate[t_idx]['id']]['bbox'] = remaining_detection[d_idx] # aggiorna la bounding box\n",
        "                        self.trackers[vanishing_list_enumerate[t_idx]['id']]['conf'] = remaining_confidences[d_idx] # aggiorna la confidence\n",
        "                        self.trackers[vanishing_list_enumerate[t_idx]['id']]['lost'] = 0 # aggiorna il numero di frame persi\n",
        "                        # tolgo da vanishing\n",
        "                        self.vanishing_tracks = [t for t in self.vanishing_tracks if t['id'] != vanishing_list_enumerate[t_idx]['id']]\n",
        "                    else:\n",
        "                        # print(f\"Valore sopra la soglia per la re-id: {norm_cost_matrix_reid[t_idx, d_idx]}\")\n",
        "                        # se non reidentifico allora devo creare una nuova detection\n",
        "                        # print(\"New detection!\")\n",
        "                        new_track = {'bbox': remaining_detection[d_idx], 'id': self.track_counter, 'conf': remaining_confidences[d_idx], 'lost':0}\n",
        "                        self.trackers.append(new_track)\n",
        "                        self.track_counter += 1\n",
        "\n",
        "\n",
        "                # Crea dei set di detections non matchate con le vanishing, quindi nuove detections\n",
        "                unmatched_unmatched_detections = set(range(len(remaining_detection))) - set(col_indices)\n",
        "\n",
        "                # adesso provo a matchare e unmatchare con i vanishing\n",
        "                # se matchano allora provvedo a reinserire nel tracker l'id a lost=0,\n",
        "                # aggiorno la confidence e la boundary box sulla base della matchata\n",
        "                # altrimenti la devo assegnae nuova\n",
        "                for d_idx in unmatched_unmatched_detections:\n",
        "                    # print(\"New detection after re-id not found!\")\n",
        "                    new_track = {'bbox': remaining_detection[d_idx], 'id': self.track_counter, 'conf': remaining_confidences[d_idx], 'lost':0}\n",
        "                    self.trackers.append(new_track)\n",
        "                    self.track_counter += 1\n",
        "            else:\n",
        "                # ancora non ci sono track scomparse\n",
        "                for d_idx in unmatched_detections:\n",
        "                    # print(\"New detection!\")\n",
        "                    new_track = {'bbox': detections[d_idx], 'id': self.track_counter, 'conf':confidences[d_idx], 'lost':0}\n",
        "                    self.trackers.append(new_track)\n",
        "                    self.track_counter += 1\n",
        "\n",
        "            vanished_keys = [vanished['id'] for vanished in self.vanishing_tracks]\n",
        "            # Aumenta il contatore per i tracker persi\n",
        "            for t_idx in unmatched_trackers:\n",
        "                # print(\"breakpoint3\")\n",
        "                # print(bbx)\n",
        "                id_track = current_frames[t_idx]['id']\n",
        "                # print(f\"Lost track id: {t_idx}\")\n",
        "                self.trackers[id_track]['lost'] += 1\n",
        "                bbx = self.trackers[id_track]['bbox']\n",
        "                if t_idx not in vanished_keys:\n",
        "                    feature_lost = vgg16.extract_features(frame,bbx)\n",
        "                    lost_track = {'id':id_track, 'bbox': self.trackers[id_track]['bbox'], 'conf': self.trackers[id_track]['conf'], 'feature': feature_lost}\n",
        "                    self.vanishing_tracks.append(lost_track)\n",
        "\n",
        "            # devo aggiornare i track persi di quelli già persi\n",
        "            # for idx in range(len(self.trackers)):\n",
        "            #     if self.trackers[idx]['lost'] > 0:\n",
        "            #         self.trackers[idx]['lost'] += 1\n",
        "\n",
        "            # rivedere un attimo perché se tolgo un track allora la lista è più piccola\n",
        "            # Rimuovi gli oggetti non tracciati per troppo tempo\n",
        "            # self.trackers = [t for t in self.trackers if t['lost'] <= self.max_lost_frames]\n",
        "            keep_tracks = []\n",
        "            for t in self.trackers:\n",
        "                if t['lost'] > self.max_lost_frames:\n",
        "                    self.dead_tracks.append(t['id'])\n",
        "                    id_dead = t['id']\n",
        "                    # print(f'Morta la track {id_dead}')\n",
        "                if t['lost'] > 0 and t['lost'] <= self.max_lost_frames:\n",
        "                    keep_tracks.append(t['id'])\n",
        "            # per test, le dead track impostano a [] l'id corrispondente:\n",
        "            for id_dead in self.dead_tracks:\n",
        "                self.trackers[id_dead] = []\n",
        "            # tolgo da vanishing le track perse ma non ancora morte\n",
        "            self.vanishing_tracks = [t for t in self.vanishing_tracks if t['id'] in keep_tracks]\n",
        "            # print(f'Track perse conservate: {self.vanishing_tracks}')\n",
        "\n",
        "\n",
        "    def compute_cost(self, tracker, detection):\n",
        "        t_x1, t_y1, t_x2, t_y2 = tracker\n",
        "        d_x1, d_y1, d_x2, d_y2 = detection\n",
        "        iou = self.iou(tracker, detection)\n",
        "        # dist = np.linalg.norm(np.array([(t_x1+t_x2)/2, (t_y1+t_y2)/2]) - np.array([(d_x1+d_x2)/2, (d_y1+d_y2)/2]))\n",
        "        return (1-iou) # la distanza varia tra 0 e 1\n",
        "\n",
        "    def iou(self, box1, box2):\n",
        "        x1 = max(box1[0], box2[0])\n",
        "        y1 = max(box1[1], box2[1])\n",
        "        x2 = min(box1[2], box2[2])\n",
        "        y2 = min(box1[3], box2[3])\n",
        "        inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "        union_area = box1_area + box2_area - inter_area\n",
        "        return inter_area / union_area if union_area != 0 else 0"
      ],
      "metadata": {
        "id": "qCcDKXqzYhB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.font_manager as fm\n",
        "import numpy as np\n",
        "\n",
        "def plot_image_w_detections(image, detections):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "    for detection in detections:\n",
        "        frame,id,x,y,w,h,conf,_,_,_ = detection\n",
        "        rectangle = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='green', facecolor='none')\n",
        "        ax.add_patch(rectangle)\n",
        "\n",
        "        # Step 4: Add text\n",
        "        # Define the text and its position\n",
        "        text = f\"id: {id}, conf:{conf:.2f}\"\n",
        "        text_position = (x, y-10)  # Position the text at the top-left corner with some padding\n",
        "        # Add the text to the plot with alignment properties\n",
        "        ax.text(*text_position, text, fontsize=5, color='green',\n",
        "        verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.5))\n",
        "\n",
        "\n",
        "    # Step 5: Display the image\n",
        "    plt.axis('off')  # Turn off the axis\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pIqUEhtv0a1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_image_folder(folder_path, frame_size=(640, 360), detection_interval=2, frame_limit_flag = False, limit=5):\n",
        "#     tracker = Tracker()\n",
        "#     frame_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "#     frame_count = 0\n",
        "\n",
        "#     detections_frame = []\n",
        "\n",
        "#     detections_preload = []\n",
        "\n",
        "#     idx = 0\n",
        "#     # preload frames\n",
        "#     for frame_file in frame_files:\n",
        "#         frame = Image.open(frame_file)\n",
        "#         print(idx)\n",
        "#         confidences, detections = detect_pedestrians(im=frame, model=model,threshold_confidence=0.6)\n",
        "#         detections_preload.append([confidences, detections])\n",
        "#         idx += 1\n",
        "\n",
        "#     print('Fine preload')\n",
        "#     for frame_file in frame_files:\n",
        "#         if frame_limit_flag and frame_count > limit:\n",
        "#             break\n",
        "#         frame = Image.open(frame_file)\n",
        "\n",
        "#         if frame_count % detection_interval == 0:\n",
        "#             # confidences, detections = detect_pedestrians(im=frame, model=model)\n",
        "#             confidences, detections = detections_preload[frame_count]\n",
        "#         tracker.update_tracker(confidences, detections, frame, vgg16, theshold_det_track = 0.4, theshold_reid=0.4)\n",
        "\n",
        "#         actual_detections = [] # solo per print\n",
        "\n",
        "#         for track in tracker.trackers:\n",
        "#             if track['lost'] == 0:\n",
        "#                 x1, y1, x2, y2 = map(int, track['bbox'])\n",
        "#                 x = x1\n",
        "#                 y = y1\n",
        "#                 w = x2-x1\n",
        "#                 h = y2-y1\n",
        "#                 conf = track['conf']\n",
        "#                 # poi format_detection deve essere stampato in un file\n",
        "#                 format_detectetion = [frame_count, track['id'], x,y,w,h, track['conf'],-1,-1,-1]\n",
        "#                 print(format_detectetion)\n",
        "#                 actual_detections.append(format_detectetion) # solo per printing\n",
        "#                 detections_frame.append(format_detectetion)\n",
        "#         print(f'Frame: {frame_count}')\n",
        "#         # plot_image_w_detections(frame, actual_detections)\n",
        "#         frame_count += 1\n",
        "#     return detections_frame"
      ],
      "metadata": {
        "id": "nxiUblwmYqh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1yOq9ajLlKMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OwcGehz_97e",
        "outputId": "58f97f83-31a1-4e00-a296-54d4b13895f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/images'\n",
        "# detected_to_file = process_image_folder(path, frame_size=(1920, 1080), detection_interval=1, frame_limit_flag=True, limit=40)"
      ],
      "metadata": {
        "id": "IUgnU3ZmYuIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_detections(folder_path, t):\n",
        "    frame_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "    frame_count = 0\n",
        "\n",
        "    detections_preload = []\n",
        "\n",
        "    idx = 0\n",
        "    # preload frames\n",
        "    for frame_file in frame_files:\n",
        "        frame = Image.open(frame_file)\n",
        "        print(f'Frame: {idx}')\n",
        "        confidences, detections = detect_pedestrians(t, im=frame, model=model)\n",
        "        detection_per_frame = []\n",
        "        for i in range(len(detections)):\n",
        "            detection_per_frame.append([detections[i], confidences[i]])\n",
        "        detections_preload.append(detection_per_frame)\n",
        "        idx += 1\n",
        "    return detections_preload"
      ],
      "metadata": {
        "id": "EqwKch9obFa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/MOT17-13-DPM'\n",
        "detections = extract_detections(path, t=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cutmpc7eVRo",
        "outputId": "59ec8063-91a7-4838-ca78-94db7a575214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame: 0\n",
            "Frame: 1\n",
            "Frame: 2\n",
            "Frame: 3\n",
            "Frame: 4\n",
            "Frame: 5\n",
            "Frame: 6\n",
            "Frame: 7\n",
            "Frame: 8\n",
            "Frame: 9\n",
            "Frame: 10\n",
            "Frame: 11\n",
            "Frame: 12\n",
            "Frame: 13\n",
            "Frame: 14\n",
            "Frame: 15\n",
            "Frame: 16\n",
            "Frame: 17\n",
            "Frame: 18\n",
            "Frame: 19\n",
            "Frame: 20\n",
            "Frame: 21\n",
            "Frame: 22\n",
            "Frame: 23\n",
            "Frame: 24\n",
            "Frame: 25\n",
            "Frame: 26\n",
            "Frame: 27\n",
            "Frame: 28\n",
            "Frame: 29\n",
            "Frame: 30\n",
            "Frame: 31\n",
            "Frame: 32\n",
            "Frame: 33\n",
            "Frame: 34\n",
            "Frame: 35\n",
            "Frame: 36\n",
            "Frame: 37\n",
            "Frame: 38\n",
            "Frame: 39\n",
            "Frame: 40\n",
            "Frame: 41\n",
            "Frame: 42\n",
            "Frame: 43\n",
            "Frame: 44\n",
            "Frame: 45\n",
            "Frame: 46\n",
            "Frame: 47\n",
            "Frame: 48\n",
            "Frame: 49\n",
            "Frame: 50\n",
            "Frame: 51\n",
            "Frame: 52\n",
            "Frame: 53\n",
            "Frame: 54\n",
            "Frame: 55\n",
            "Frame: 56\n",
            "Frame: 57\n",
            "Frame: 58\n",
            "Frame: 59\n",
            "Frame: 60\n",
            "Frame: 61\n",
            "Frame: 62\n",
            "Frame: 63\n",
            "Frame: 64\n",
            "Frame: 65\n",
            "Frame: 66\n",
            "Frame: 67\n",
            "Frame: 68\n",
            "Frame: 69\n",
            "Frame: 70\n",
            "Frame: 71\n",
            "Frame: 72\n",
            "Frame: 73\n",
            "Frame: 74\n",
            "Frame: 75\n",
            "Frame: 76\n",
            "Frame: 77\n",
            "Frame: 78\n",
            "Frame: 79\n",
            "Frame: 80\n",
            "Frame: 81\n",
            "Frame: 82\n",
            "Frame: 83\n",
            "Frame: 84\n",
            "Frame: 85\n",
            "Frame: 86\n",
            "Frame: 87\n",
            "Frame: 88\n",
            "Frame: 89\n",
            "Frame: 90\n",
            "Frame: 91\n",
            "Frame: 92\n",
            "Frame: 93\n",
            "Frame: 94\n",
            "Frame: 95\n",
            "Frame: 96\n",
            "Frame: 97\n",
            "Frame: 98\n",
            "Frame: 99\n",
            "Frame: 100\n",
            "Frame: 101\n",
            "Frame: 102\n",
            "Frame: 103\n",
            "Frame: 104\n",
            "Frame: 105\n",
            "Frame: 106\n",
            "Frame: 107\n",
            "Frame: 108\n",
            "Frame: 109\n",
            "Frame: 110\n",
            "Frame: 111\n",
            "Frame: 112\n",
            "Frame: 113\n",
            "Frame: 114\n",
            "Frame: 115\n",
            "Frame: 116\n",
            "Frame: 117\n",
            "Frame: 118\n",
            "Frame: 119\n",
            "Frame: 120\n",
            "Frame: 121\n",
            "Frame: 122\n",
            "Frame: 123\n",
            "Frame: 124\n",
            "Frame: 125\n",
            "Frame: 126\n",
            "Frame: 127\n",
            "Frame: 128\n",
            "Frame: 129\n",
            "Frame: 130\n",
            "Frame: 131\n",
            "Frame: 132\n",
            "Frame: 133\n",
            "Frame: 134\n",
            "Frame: 135\n",
            "Frame: 136\n",
            "Frame: 137\n",
            "Frame: 138\n",
            "Frame: 139\n",
            "Frame: 140\n",
            "Frame: 141\n",
            "Frame: 142\n",
            "Frame: 143\n",
            "Frame: 144\n",
            "Frame: 145\n",
            "Frame: 146\n",
            "Frame: 147\n",
            "Frame: 148\n",
            "Frame: 149\n",
            "Frame: 150\n",
            "Frame: 151\n",
            "Frame: 152\n",
            "Frame: 153\n",
            "Frame: 154\n",
            "Frame: 155\n",
            "Frame: 156\n",
            "Frame: 157\n",
            "Frame: 158\n",
            "Frame: 159\n",
            "Frame: 160\n",
            "Frame: 161\n",
            "Frame: 162\n",
            "Frame: 163\n",
            "Frame: 164\n",
            "Frame: 165\n",
            "Frame: 166\n",
            "Frame: 167\n",
            "Frame: 168\n",
            "Frame: 169\n",
            "Frame: 170\n",
            "Frame: 171\n",
            "Frame: 172\n",
            "Frame: 173\n",
            "Frame: 174\n",
            "Frame: 175\n",
            "Frame: 176\n",
            "Frame: 177\n",
            "Frame: 178\n",
            "Frame: 179\n",
            "Frame: 180\n",
            "Frame: 181\n",
            "Frame: 182\n",
            "Frame: 183\n",
            "Frame: 184\n",
            "Frame: 185\n",
            "Frame: 186\n",
            "Frame: 187\n",
            "Frame: 188\n",
            "Frame: 189\n",
            "Frame: 190\n",
            "Frame: 191\n",
            "Frame: 192\n",
            "Frame: 193\n",
            "Frame: 194\n",
            "Frame: 195\n",
            "Frame: 196\n",
            "Frame: 197\n",
            "Frame: 198\n",
            "Frame: 199\n",
            "Frame: 200\n",
            "Frame: 201\n",
            "Frame: 202\n",
            "Frame: 203\n",
            "Frame: 204\n",
            "Frame: 205\n",
            "Frame: 206\n",
            "Frame: 207\n",
            "Frame: 208\n",
            "Frame: 209\n",
            "Frame: 210\n",
            "Frame: 211\n",
            "Frame: 212\n",
            "Frame: 213\n",
            "Frame: 214\n",
            "Frame: 215\n",
            "Frame: 216\n",
            "Frame: 217\n",
            "Frame: 218\n",
            "Frame: 219\n",
            "Frame: 220\n",
            "Frame: 221\n",
            "Frame: 222\n",
            "Frame: 223\n",
            "Frame: 224\n",
            "Frame: 225\n",
            "Frame: 226\n",
            "Frame: 227\n",
            "Frame: 228\n",
            "Frame: 229\n",
            "Frame: 230\n",
            "Frame: 231\n",
            "Frame: 232\n",
            "Frame: 233\n",
            "Frame: 234\n",
            "Frame: 235\n",
            "Frame: 236\n",
            "Frame: 237\n",
            "Frame: 238\n",
            "Frame: 239\n",
            "Frame: 240\n",
            "Frame: 241\n",
            "Frame: 242\n",
            "Frame: 243\n",
            "Frame: 244\n",
            "Frame: 245\n",
            "Frame: 246\n",
            "Frame: 247\n",
            "Frame: 248\n",
            "Frame: 249\n",
            "Frame: 250\n",
            "Frame: 251\n",
            "Frame: 252\n",
            "Frame: 253\n",
            "Frame: 254\n",
            "Frame: 255\n",
            "Frame: 256\n",
            "Frame: 257\n",
            "Frame: 258\n",
            "Frame: 259\n",
            "Frame: 260\n",
            "Frame: 261\n",
            "Frame: 262\n",
            "Frame: 263\n",
            "Frame: 264\n",
            "Frame: 265\n",
            "Frame: 266\n",
            "Frame: 267\n",
            "Frame: 268\n",
            "Frame: 269\n",
            "Frame: 270\n",
            "Frame: 271\n",
            "Frame: 272\n",
            "Frame: 273\n",
            "Frame: 274\n",
            "Frame: 275\n",
            "Frame: 276\n",
            "Frame: 277\n",
            "Frame: 278\n",
            "Frame: 279\n",
            "Frame: 280\n",
            "Frame: 281\n",
            "Frame: 282\n",
            "Frame: 283\n",
            "Frame: 284\n",
            "Frame: 285\n",
            "Frame: 286\n",
            "Frame: 287\n",
            "Frame: 288\n",
            "Frame: 289\n",
            "Frame: 290\n",
            "Frame: 291\n",
            "Frame: 292\n",
            "Frame: 293\n",
            "Frame: 294\n",
            "Frame: 295\n",
            "Frame: 296\n",
            "Frame: 297\n",
            "Frame: 298\n",
            "Frame: 299\n",
            "Frame: 300\n",
            "Frame: 301\n",
            "Frame: 302\n",
            "Frame: 303\n",
            "Frame: 304\n",
            "Frame: 305\n",
            "Frame: 306\n",
            "Frame: 307\n",
            "Frame: 308\n",
            "Frame: 309\n",
            "Frame: 310\n",
            "Frame: 311\n",
            "Frame: 312\n",
            "Frame: 313\n",
            "Frame: 314\n",
            "Frame: 315\n",
            "Frame: 316\n",
            "Frame: 317\n",
            "Frame: 318\n",
            "Frame: 319\n",
            "Frame: 320\n",
            "Frame: 321\n",
            "Frame: 322\n",
            "Frame: 323\n",
            "Frame: 324\n",
            "Frame: 325\n",
            "Frame: 326\n",
            "Frame: 327\n",
            "Frame: 328\n",
            "Frame: 329\n",
            "Frame: 330\n",
            "Frame: 331\n",
            "Frame: 332\n",
            "Frame: 333\n",
            "Frame: 334\n",
            "Frame: 335\n",
            "Frame: 336\n",
            "Frame: 337\n",
            "Frame: 338\n",
            "Frame: 339\n",
            "Frame: 340\n",
            "Frame: 341\n",
            "Frame: 342\n",
            "Frame: 343\n",
            "Frame: 344\n",
            "Frame: 345\n",
            "Frame: 346\n",
            "Frame: 347\n",
            "Frame: 348\n",
            "Frame: 349\n",
            "Frame: 350\n",
            "Frame: 351\n",
            "Frame: 352\n",
            "Frame: 353\n",
            "Frame: 354\n",
            "Frame: 355\n",
            "Frame: 356\n",
            "Frame: 357\n",
            "Frame: 358\n",
            "Frame: 359\n",
            "Frame: 360\n",
            "Frame: 361\n",
            "Frame: 362\n",
            "Frame: 363\n",
            "Frame: 364\n",
            "Frame: 365\n",
            "Frame: 366\n",
            "Frame: 367\n",
            "Frame: 368\n",
            "Frame: 369\n",
            "Frame: 370\n",
            "Frame: 371\n",
            "Frame: 372\n",
            "Frame: 373\n",
            "Frame: 374\n",
            "Frame: 375\n",
            "Frame: 376\n",
            "Frame: 377\n",
            "Frame: 378\n",
            "Frame: 379\n",
            "Frame: 380\n",
            "Frame: 381\n",
            "Frame: 382\n",
            "Frame: 383\n",
            "Frame: 384\n",
            "Frame: 385\n",
            "Frame: 386\n",
            "Frame: 387\n",
            "Frame: 388\n",
            "Frame: 389\n",
            "Frame: 390\n",
            "Frame: 391\n",
            "Frame: 392\n",
            "Frame: 393\n",
            "Frame: 394\n",
            "Frame: 395\n",
            "Frame: 396\n",
            "Frame: 397\n",
            "Frame: 398\n",
            "Frame: 399\n",
            "Frame: 400\n",
            "Frame: 401\n",
            "Frame: 402\n",
            "Frame: 403\n",
            "Frame: 404\n",
            "Frame: 405\n",
            "Frame: 406\n",
            "Frame: 407\n",
            "Frame: 408\n",
            "Frame: 409\n",
            "Frame: 410\n",
            "Frame: 411\n",
            "Frame: 412\n",
            "Frame: 413\n",
            "Frame: 414\n",
            "Frame: 415\n",
            "Frame: 416\n",
            "Frame: 417\n",
            "Frame: 418\n",
            "Frame: 419\n",
            "Frame: 420\n",
            "Frame: 421\n",
            "Frame: 422\n",
            "Frame: 423\n",
            "Frame: 424\n",
            "Frame: 425\n",
            "Frame: 426\n",
            "Frame: 427\n",
            "Frame: 428\n",
            "Frame: 429\n",
            "Frame: 430\n",
            "Frame: 431\n",
            "Frame: 432\n",
            "Frame: 433\n",
            "Frame: 434\n",
            "Frame: 435\n",
            "Frame: 436\n",
            "Frame: 437\n",
            "Frame: 438\n",
            "Frame: 439\n",
            "Frame: 440\n",
            "Frame: 441\n",
            "Frame: 442\n",
            "Frame: 443\n",
            "Frame: 444\n",
            "Frame: 445\n",
            "Frame: 446\n",
            "Frame: 447\n",
            "Frame: 448\n",
            "Frame: 449\n",
            "Frame: 450\n",
            "Frame: 451\n",
            "Frame: 452\n",
            "Frame: 453\n",
            "Frame: 454\n",
            "Frame: 455\n",
            "Frame: 456\n",
            "Frame: 457\n",
            "Frame: 458\n",
            "Frame: 459\n",
            "Frame: 460\n",
            "Frame: 461\n",
            "Frame: 462\n",
            "Frame: 463\n",
            "Frame: 464\n",
            "Frame: 465\n",
            "Frame: 466\n",
            "Frame: 467\n",
            "Frame: 468\n",
            "Frame: 469\n",
            "Frame: 470\n",
            "Frame: 471\n",
            "Frame: 472\n",
            "Frame: 473\n",
            "Frame: 474\n",
            "Frame: 475\n",
            "Frame: 476\n",
            "Frame: 477\n",
            "Frame: 478\n",
            "Frame: 479\n",
            "Frame: 480\n",
            "Frame: 481\n",
            "Frame: 482\n",
            "Frame: 483\n",
            "Frame: 484\n",
            "Frame: 485\n",
            "Frame: 486\n",
            "Frame: 487\n",
            "Frame: 488\n",
            "Frame: 489\n",
            "Frame: 490\n",
            "Frame: 491\n",
            "Frame: 492\n",
            "Frame: 493\n",
            "Frame: 494\n",
            "Frame: 495\n",
            "Frame: 496\n",
            "Frame: 497\n",
            "Frame: 498\n",
            "Frame: 499\n",
            "Frame: 500\n",
            "Frame: 501\n",
            "Frame: 502\n",
            "Frame: 503\n",
            "Frame: 504\n",
            "Frame: 505\n",
            "Frame: 506\n",
            "Frame: 507\n",
            "Frame: 508\n",
            "Frame: 509\n",
            "Frame: 510\n",
            "Frame: 511\n",
            "Frame: 512\n",
            "Frame: 513\n",
            "Frame: 514\n",
            "Frame: 515\n",
            "Frame: 516\n",
            "Frame: 517\n",
            "Frame: 518\n",
            "Frame: 519\n",
            "Frame: 520\n",
            "Frame: 521\n",
            "Frame: 522\n",
            "Frame: 523\n",
            "Frame: 524\n",
            "Frame: 525\n",
            "Frame: 526\n",
            "Frame: 527\n",
            "Frame: 528\n",
            "Frame: 529\n",
            "Frame: 530\n",
            "Frame: 531\n",
            "Frame: 532\n",
            "Frame: 533\n",
            "Frame: 534\n",
            "Frame: 535\n",
            "Frame: 536\n",
            "Frame: 537\n",
            "Frame: 538\n",
            "Frame: 539\n",
            "Frame: 540\n",
            "Frame: 541\n",
            "Frame: 542\n",
            "Frame: 543\n",
            "Frame: 544\n",
            "Frame: 545\n",
            "Frame: 546\n",
            "Frame: 547\n",
            "Frame: 548\n",
            "Frame: 549\n",
            "Frame: 550\n",
            "Frame: 551\n",
            "Frame: 552\n",
            "Frame: 553\n",
            "Frame: 554\n",
            "Frame: 555\n",
            "Frame: 556\n",
            "Frame: 557\n",
            "Frame: 558\n",
            "Frame: 559\n",
            "Frame: 560\n",
            "Frame: 561\n",
            "Frame: 562\n",
            "Frame: 563\n",
            "Frame: 564\n",
            "Frame: 565\n",
            "Frame: 566\n",
            "Frame: 567\n",
            "Frame: 568\n",
            "Frame: 569\n",
            "Frame: 570\n",
            "Frame: 571\n",
            "Frame: 572\n",
            "Frame: 573\n",
            "Frame: 574\n",
            "Frame: 575\n",
            "Frame: 576\n",
            "Frame: 577\n",
            "Frame: 578\n",
            "Frame: 579\n",
            "Frame: 580\n",
            "Frame: 581\n",
            "Frame: 582\n",
            "Frame: 583\n",
            "Frame: 584\n",
            "Frame: 585\n",
            "Frame: 586\n",
            "Frame: 587\n",
            "Frame: 588\n",
            "Frame: 589\n",
            "Frame: 590\n",
            "Frame: 591\n",
            "Frame: 592\n",
            "Frame: 593\n",
            "Frame: 594\n",
            "Frame: 595\n",
            "Frame: 596\n",
            "Frame: 597\n",
            "Frame: 598\n",
            "Frame: 599\n",
            "Frame: 600\n",
            "Frame: 601\n",
            "Frame: 602\n",
            "Frame: 603\n",
            "Frame: 604\n",
            "Frame: 605\n",
            "Frame: 606\n",
            "Frame: 607\n",
            "Frame: 608\n",
            "Frame: 609\n",
            "Frame: 610\n",
            "Frame: 611\n",
            "Frame: 612\n",
            "Frame: 613\n",
            "Frame: 614\n",
            "Frame: 615\n",
            "Frame: 616\n",
            "Frame: 617\n",
            "Frame: 618\n",
            "Frame: 619\n",
            "Frame: 620\n",
            "Frame: 621\n",
            "Frame: 622\n",
            "Frame: 623\n",
            "Frame: 624\n",
            "Frame: 625\n",
            "Frame: 626\n",
            "Frame: 627\n",
            "Frame: 628\n",
            "Frame: 629\n",
            "Frame: 630\n",
            "Frame: 631\n",
            "Frame: 632\n",
            "Frame: 633\n",
            "Frame: 634\n",
            "Frame: 635\n",
            "Frame: 636\n",
            "Frame: 637\n",
            "Frame: 638\n",
            "Frame: 639\n",
            "Frame: 640\n",
            "Frame: 641\n",
            "Frame: 642\n",
            "Frame: 643\n",
            "Frame: 644\n",
            "Frame: 645\n",
            "Frame: 646\n",
            "Frame: 647\n",
            "Frame: 648\n",
            "Frame: 649\n",
            "Frame: 650\n",
            "Frame: 651\n",
            "Frame: 652\n",
            "Frame: 653\n",
            "Frame: 654\n",
            "Frame: 655\n",
            "Frame: 656\n",
            "Frame: 657\n",
            "Frame: 658\n",
            "Frame: 659\n",
            "Frame: 660\n",
            "Frame: 661\n",
            "Frame: 662\n",
            "Frame: 663\n",
            "Frame: 664\n",
            "Frame: 665\n",
            "Frame: 666\n",
            "Frame: 667\n",
            "Frame: 668\n",
            "Frame: 669\n",
            "Frame: 670\n",
            "Frame: 671\n",
            "Frame: 672\n",
            "Frame: 673\n",
            "Frame: 674\n",
            "Frame: 675\n",
            "Frame: 676\n",
            "Frame: 677\n",
            "Frame: 678\n",
            "Frame: 679\n",
            "Frame: 680\n",
            "Frame: 681\n",
            "Frame: 682\n",
            "Frame: 683\n",
            "Frame: 684\n",
            "Frame: 685\n",
            "Frame: 686\n",
            "Frame: 687\n",
            "Frame: 688\n",
            "Frame: 689\n",
            "Frame: 690\n",
            "Frame: 691\n",
            "Frame: 692\n",
            "Frame: 693\n",
            "Frame: 694\n",
            "Frame: 695\n",
            "Frame: 696\n",
            "Frame: 697\n",
            "Frame: 698\n",
            "Frame: 699\n",
            "Frame: 700\n",
            "Frame: 701\n",
            "Frame: 702\n",
            "Frame: 703\n",
            "Frame: 704\n",
            "Frame: 705\n",
            "Frame: 706\n",
            "Frame: 707\n",
            "Frame: 708\n",
            "Frame: 709\n",
            "Frame: 710\n",
            "Frame: 711\n",
            "Frame: 712\n",
            "Frame: 713\n",
            "Frame: 714\n",
            "Frame: 715\n",
            "Frame: 716\n",
            "Frame: 717\n",
            "Frame: 718\n",
            "Frame: 719\n",
            "Frame: 720\n",
            "Frame: 721\n",
            "Frame: 722\n",
            "Frame: 723\n",
            "Frame: 724\n",
            "Frame: 725\n",
            "Frame: 726\n",
            "Frame: 727\n",
            "Frame: 728\n",
            "Frame: 729\n",
            "Frame: 730\n",
            "Frame: 731\n",
            "Frame: 732\n",
            "Frame: 733\n",
            "Frame: 734\n",
            "Frame: 735\n",
            "Frame: 736\n",
            "Frame: 737\n",
            "Frame: 738\n",
            "Frame: 739\n",
            "Frame: 740\n",
            "Frame: 741\n",
            "Frame: 742\n",
            "Frame: 743\n",
            "Frame: 744\n",
            "Frame: 745\n",
            "Frame: 746\n",
            "Frame: 747\n",
            "Frame: 748\n",
            "Frame: 749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(detections[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adLYgxvsYXoO",
        "outputId": "a51e8c49-6e73-4166-df48-e9fcd9fb2151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detections[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkVuNUjAZrxP",
        "outputId": "d69e76a4-1fcd-44e2-d999-77d556c59bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[array([620.2601 , 512.24786, 652.8814 , 591.8727 ], dtype=float32),\n",
              "  0.7455426],\n",
              " [array([114.685074, 706.71155 , 166.86876 , 811.7171  ], dtype=float32),\n",
              "  0.95309377],\n",
              " [array([1478.754 ,  531.1471, 1505.6257,  592.4311], dtype=float32),\n",
              "  0.673282],\n",
              " [array([1520.455  ,  561.87054, 1573.9979 ,  676.2484 ], dtype=float32),\n",
              "  0.9929877],\n",
              " [array([1188.8218 ,  480.20657, 1216.8882 ,  524.50116], dtype=float32),\n",
              "  0.6201036],\n",
              " [array([1606.1079 ,  548.58936, 1661.0089 ,  672.6865 ], dtype=float32),\n",
              "  0.96573234],\n",
              " [array([807.858  , 510.21274, 828.41016, 554.18964], dtype=float32),\n",
              "  0.6713118],\n",
              " [array([1482.962 ,  530.7892, 1512.114 ,  593.698 ], dtype=float32),\n",
              "  0.747867],\n",
              " [array([529.63086, 540.6116 , 570.0233 , 638.152  ], dtype=float32),\n",
              "  0.91629726],\n",
              " [array([191.47488, 582.7254 , 235.80142, 723.93726], dtype=float32),\n",
              "  0.91684836],\n",
              " [array([1324.0713 ,  498.18338, 1345.5214 ,  552.0971 ], dtype=float32),\n",
              "  0.67825186],\n",
              " [array([1.3235271e-01, 6.6901166e+02, 5.1526787e+01, 8.9089240e+02],\n",
              "        dtype=float32),\n",
              "  0.8892676],\n",
              " [array([668.7138 , 507.97034, 697.1187 , 589.1044 ], dtype=float32),\n",
              "  0.8256269],\n",
              " [array([499.80045, 546.8022 , 536.92816, 638.4853 ], dtype=float32),\n",
              "  0.91005605],\n",
              " [array([531.0089 , 539.27576, 569.65204, 636.565  ], dtype=float32),\n",
              "  0.93053734],\n",
              " [array([650.52057, 510.0329 , 681.95624, 592.47253], dtype=float32),\n",
              "  0.6576684],\n",
              " [array([267.65192, 586.2602 , 311.87354, 726.62646], dtype=float32),\n",
              "  0.898973],\n",
              " [array([1371.6278 ,  517.39514, 1406.2524 ,  616.5487 ], dtype=float32),\n",
              "  0.9933651],\n",
              " [array([1859.9495 ,  557.80145, 1917.9968 ,  675.73773], dtype=float32),\n",
              "  0.92433435],\n",
              " [array([593.014  , 515.33887, 622.7099 , 593.4586 ], dtype=float32),\n",
              "  0.66480476],\n",
              " [array([1069.6588 ,  486.78595, 1092.8688 ,  520.71716], dtype=float32),\n",
              "  0.6986119],\n",
              " [array([1443.7839 ,  506.57288, 1472.9043 ,  581.10535], dtype=float32),\n",
              "  0.96848035],\n",
              " [array([1176.975 ,  479.8104, 1204.717 ,  524.5239], dtype=float32),\n",
              "  0.7796168]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/master_unipa/MOT17-13-DPM/MOT17-13-DPM-DETR06.txt', 'w') as f:\n",
        "    frame_count = 0\n",
        "    for detections_frame in detections:\n",
        "        # indice del frame, detections e confidences\n",
        "        for i in range(len(detections_frame)):\n",
        "            print(f'{frame_count}, {detections_frame[i][0]}, {detections_frame[i][1]}', file=f)\n",
        "        frame_count += 1\n",
        "        # for conf, detect in zip(confidences, detections):\n",
        "        #     print(f'{detect},{conf}', file=f)"
      ],
      "metadata": {
        "id": "SvplSwuUhuiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/MOT17-09-DPM'"
      ],
      "metadata": {
        "id": "2Tga7NJaSxuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detetions = extract_detections(path, t=0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f3KqUaNTrPK",
        "outputId": "c6c5a12e-55a4-43bc-8053-90d4b41df11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame: 0\n",
            "Frame: 1\n",
            "Frame: 2\n",
            "Frame: 3\n",
            "Frame: 4\n",
            "Frame: 5\n",
            "Frame: 6\n",
            "Frame: 7\n",
            "Frame: 8\n",
            "Frame: 9\n",
            "Frame: 10\n",
            "Frame: 11\n",
            "Frame: 12\n",
            "Frame: 13\n",
            "Frame: 14\n",
            "Frame: 15\n",
            "Frame: 16\n",
            "Frame: 17\n",
            "Frame: 18\n",
            "Frame: 19\n",
            "Frame: 20\n",
            "Frame: 21\n",
            "Frame: 22\n",
            "Frame: 23\n",
            "Frame: 24\n",
            "Frame: 25\n",
            "Frame: 26\n",
            "Frame: 27\n",
            "Frame: 28\n",
            "Frame: 29\n",
            "Frame: 30\n",
            "Frame: 31\n",
            "Frame: 32\n",
            "Frame: 33\n",
            "Frame: 34\n",
            "Frame: 35\n",
            "Frame: 36\n",
            "Frame: 37\n",
            "Frame: 38\n",
            "Frame: 39\n",
            "Frame: 40\n",
            "Frame: 41\n",
            "Frame: 42\n",
            "Frame: 43\n",
            "Frame: 44\n",
            "Frame: 45\n",
            "Frame: 46\n",
            "Frame: 47\n",
            "Frame: 48\n",
            "Frame: 49\n",
            "Frame: 50\n",
            "Frame: 51\n",
            "Frame: 52\n",
            "Frame: 53\n",
            "Frame: 54\n",
            "Frame: 55\n",
            "Frame: 56\n",
            "Frame: 57\n",
            "Frame: 58\n",
            "Frame: 59\n",
            "Frame: 60\n",
            "Frame: 61\n",
            "Frame: 62\n",
            "Frame: 63\n",
            "Frame: 64\n",
            "Frame: 65\n",
            "Frame: 66\n",
            "Frame: 67\n",
            "Frame: 68\n",
            "Frame: 69\n",
            "Frame: 70\n",
            "Frame: 71\n",
            "Frame: 72\n",
            "Frame: 73\n",
            "Frame: 74\n",
            "Frame: 75\n",
            "Frame: 76\n",
            "Frame: 77\n",
            "Frame: 78\n",
            "Frame: 79\n",
            "Frame: 80\n",
            "Frame: 81\n",
            "Frame: 82\n",
            "Frame: 83\n",
            "Frame: 84\n",
            "Frame: 85\n",
            "Frame: 86\n",
            "Frame: 87\n",
            "Frame: 88\n",
            "Frame: 89\n",
            "Frame: 90\n",
            "Frame: 91\n",
            "Frame: 92\n",
            "Frame: 93\n",
            "Frame: 94\n",
            "Frame: 95\n",
            "Frame: 96\n",
            "Frame: 97\n",
            "Frame: 98\n",
            "Frame: 99\n",
            "Frame: 100\n",
            "Frame: 101\n",
            "Frame: 102\n",
            "Frame: 103\n",
            "Frame: 104\n",
            "Frame: 105\n",
            "Frame: 106\n",
            "Frame: 107\n",
            "Frame: 108\n",
            "Frame: 109\n",
            "Frame: 110\n",
            "Frame: 111\n",
            "Frame: 112\n",
            "Frame: 113\n",
            "Frame: 114\n",
            "Frame: 115\n",
            "Frame: 116\n",
            "Frame: 117\n",
            "Frame: 118\n",
            "Frame: 119\n",
            "Frame: 120\n",
            "Frame: 121\n",
            "Frame: 122\n",
            "Frame: 123\n",
            "Frame: 124\n",
            "Frame: 125\n",
            "Frame: 126\n",
            "Frame: 127\n",
            "Frame: 128\n",
            "Frame: 129\n",
            "Frame: 130\n",
            "Frame: 131\n",
            "Frame: 132\n",
            "Frame: 133\n",
            "Frame: 134\n",
            "Frame: 135\n",
            "Frame: 136\n",
            "Frame: 137\n",
            "Frame: 138\n",
            "Frame: 139\n",
            "Frame: 140\n",
            "Frame: 141\n",
            "Frame: 142\n",
            "Frame: 143\n",
            "Frame: 144\n",
            "Frame: 145\n",
            "Frame: 146\n",
            "Frame: 147\n",
            "Frame: 148\n",
            "Frame: 149\n",
            "Frame: 150\n",
            "Frame: 151\n",
            "Frame: 152\n",
            "Frame: 153\n",
            "Frame: 154\n",
            "Frame: 155\n",
            "Frame: 156\n",
            "Frame: 157\n",
            "Frame: 158\n",
            "Frame: 159\n",
            "Frame: 160\n",
            "Frame: 161\n",
            "Frame: 162\n",
            "Frame: 163\n",
            "Frame: 164\n",
            "Frame: 165\n",
            "Frame: 166\n",
            "Frame: 167\n",
            "Frame: 168\n",
            "Frame: 169\n",
            "Frame: 170\n",
            "Frame: 171\n",
            "Frame: 172\n",
            "Frame: 173\n",
            "Frame: 174\n",
            "Frame: 175\n",
            "Frame: 176\n",
            "Frame: 177\n",
            "Frame: 178\n",
            "Frame: 179\n",
            "Frame: 180\n",
            "Frame: 181\n",
            "Frame: 182\n",
            "Frame: 183\n",
            "Frame: 184\n",
            "Frame: 185\n",
            "Frame: 186\n",
            "Frame: 187\n",
            "Frame: 188\n",
            "Frame: 189\n",
            "Frame: 190\n",
            "Frame: 191\n",
            "Frame: 192\n",
            "Frame: 193\n",
            "Frame: 194\n",
            "Frame: 195\n",
            "Frame: 196\n",
            "Frame: 197\n",
            "Frame: 198\n",
            "Frame: 199\n",
            "Frame: 200\n",
            "Frame: 201\n",
            "Frame: 202\n",
            "Frame: 203\n",
            "Frame: 204\n",
            "Frame: 205\n",
            "Frame: 206\n",
            "Frame: 207\n",
            "Frame: 208\n",
            "Frame: 209\n",
            "Frame: 210\n",
            "Frame: 211\n",
            "Frame: 212\n",
            "Frame: 213\n",
            "Frame: 214\n",
            "Frame: 215\n",
            "Frame: 216\n",
            "Frame: 217\n",
            "Frame: 218\n",
            "Frame: 219\n",
            "Frame: 220\n",
            "Frame: 221\n",
            "Frame: 222\n",
            "Frame: 223\n",
            "Frame: 224\n",
            "Frame: 225\n",
            "Frame: 226\n",
            "Frame: 227\n",
            "Frame: 228\n",
            "Frame: 229\n",
            "Frame: 230\n",
            "Frame: 231\n",
            "Frame: 232\n",
            "Frame: 233\n",
            "Frame: 234\n",
            "Frame: 235\n",
            "Frame: 236\n",
            "Frame: 237\n",
            "Frame: 238\n",
            "Frame: 239\n",
            "Frame: 240\n",
            "Frame: 241\n",
            "Frame: 242\n",
            "Frame: 243\n",
            "Frame: 244\n",
            "Frame: 245\n",
            "Frame: 246\n",
            "Frame: 247\n",
            "Frame: 248\n",
            "Frame: 249\n",
            "Frame: 250\n",
            "Frame: 251\n",
            "Frame: 252\n",
            "Frame: 253\n",
            "Frame: 254\n",
            "Frame: 255\n",
            "Frame: 256\n",
            "Frame: 257\n",
            "Frame: 258\n",
            "Frame: 259\n",
            "Frame: 260\n",
            "Frame: 261\n",
            "Frame: 262\n",
            "Frame: 263\n",
            "Frame: 264\n",
            "Frame: 265\n",
            "Frame: 266\n",
            "Frame: 267\n",
            "Frame: 268\n",
            "Frame: 269\n",
            "Frame: 270\n",
            "Frame: 271\n",
            "Frame: 272\n",
            "Frame: 273\n",
            "Frame: 274\n",
            "Frame: 275\n",
            "Frame: 276\n",
            "Frame: 277\n",
            "Frame: 278\n",
            "Frame: 279\n",
            "Frame: 280\n",
            "Frame: 281\n",
            "Frame: 282\n",
            "Frame: 283\n",
            "Frame: 284\n",
            "Frame: 285\n",
            "Frame: 286\n",
            "Frame: 287\n",
            "Frame: 288\n",
            "Frame: 289\n",
            "Frame: 290\n",
            "Frame: 291\n",
            "Frame: 292\n",
            "Frame: 293\n",
            "Frame: 294\n",
            "Frame: 295\n",
            "Frame: 296\n",
            "Frame: 297\n",
            "Frame: 298\n",
            "Frame: 299\n",
            "Frame: 300\n",
            "Frame: 301\n",
            "Frame: 302\n",
            "Frame: 303\n",
            "Frame: 304\n",
            "Frame: 305\n",
            "Frame: 306\n",
            "Frame: 307\n",
            "Frame: 308\n",
            "Frame: 309\n",
            "Frame: 310\n",
            "Frame: 311\n",
            "Frame: 312\n",
            "Frame: 313\n",
            "Frame: 314\n",
            "Frame: 315\n",
            "Frame: 316\n",
            "Frame: 317\n",
            "Frame: 318\n",
            "Frame: 319\n",
            "Frame: 320\n",
            "Frame: 321\n",
            "Frame: 322\n",
            "Frame: 323\n",
            "Frame: 324\n",
            "Frame: 325\n",
            "Frame: 326\n",
            "Frame: 327\n",
            "Frame: 328\n",
            "Frame: 329\n",
            "Frame: 330\n",
            "Frame: 331\n",
            "Frame: 332\n",
            "Frame: 333\n",
            "Frame: 334\n",
            "Frame: 335\n",
            "Frame: 336\n",
            "Frame: 337\n",
            "Frame: 338\n",
            "Frame: 339\n",
            "Frame: 340\n",
            "Frame: 341\n",
            "Frame: 342\n",
            "Frame: 343\n",
            "Frame: 344\n",
            "Frame: 345\n",
            "Frame: 346\n",
            "Frame: 347\n",
            "Frame: 348\n",
            "Frame: 349\n",
            "Frame: 350\n",
            "Frame: 351\n",
            "Frame: 352\n",
            "Frame: 353\n",
            "Frame: 354\n",
            "Frame: 355\n",
            "Frame: 356\n",
            "Frame: 357\n",
            "Frame: 358\n",
            "Frame: 359\n",
            "Frame: 360\n",
            "Frame: 361\n",
            "Frame: 362\n",
            "Frame: 363\n",
            "Frame: 364\n",
            "Frame: 365\n",
            "Frame: 366\n",
            "Frame: 367\n",
            "Frame: 368\n",
            "Frame: 369\n",
            "Frame: 370\n",
            "Frame: 371\n",
            "Frame: 372\n",
            "Frame: 373\n",
            "Frame: 374\n",
            "Frame: 375\n",
            "Frame: 376\n",
            "Frame: 377\n",
            "Frame: 378\n",
            "Frame: 379\n",
            "Frame: 380\n",
            "Frame: 381\n",
            "Frame: 382\n",
            "Frame: 383\n",
            "Frame: 384\n",
            "Frame: 385\n",
            "Frame: 386\n",
            "Frame: 387\n",
            "Frame: 388\n",
            "Frame: 389\n",
            "Frame: 390\n",
            "Frame: 391\n",
            "Frame: 392\n",
            "Frame: 393\n",
            "Frame: 394\n",
            "Frame: 395\n",
            "Frame: 396\n",
            "Frame: 397\n",
            "Frame: 398\n",
            "Frame: 399\n",
            "Frame: 400\n",
            "Frame: 401\n",
            "Frame: 402\n",
            "Frame: 403\n",
            "Frame: 404\n",
            "Frame: 405\n",
            "Frame: 406\n",
            "Frame: 407\n",
            "Frame: 408\n",
            "Frame: 409\n",
            "Frame: 410\n",
            "Frame: 411\n",
            "Frame: 412\n",
            "Frame: 413\n",
            "Frame: 414\n",
            "Frame: 415\n",
            "Frame: 416\n",
            "Frame: 417\n",
            "Frame: 418\n",
            "Frame: 419\n",
            "Frame: 420\n",
            "Frame: 421\n",
            "Frame: 422\n",
            "Frame: 423\n",
            "Frame: 424\n",
            "Frame: 425\n",
            "Frame: 426\n",
            "Frame: 427\n",
            "Frame: 428\n",
            "Frame: 429\n",
            "Frame: 430\n",
            "Frame: 431\n",
            "Frame: 432\n",
            "Frame: 433\n",
            "Frame: 434\n",
            "Frame: 435\n",
            "Frame: 436\n",
            "Frame: 437\n",
            "Frame: 438\n",
            "Frame: 439\n",
            "Frame: 440\n",
            "Frame: 441\n",
            "Frame: 442\n",
            "Frame: 443\n",
            "Frame: 444\n",
            "Frame: 445\n",
            "Frame: 446\n",
            "Frame: 447\n",
            "Frame: 448\n",
            "Frame: 449\n",
            "Frame: 450\n",
            "Frame: 451\n",
            "Frame: 452\n",
            "Frame: 453\n",
            "Frame: 454\n",
            "Frame: 455\n",
            "Frame: 456\n",
            "Frame: 457\n",
            "Frame: 458\n",
            "Frame: 459\n",
            "Frame: 460\n",
            "Frame: 461\n",
            "Frame: 462\n",
            "Frame: 463\n",
            "Frame: 464\n",
            "Frame: 465\n",
            "Frame: 466\n",
            "Frame: 467\n",
            "Frame: 468\n",
            "Frame: 469\n",
            "Frame: 470\n",
            "Frame: 471\n",
            "Frame: 472\n",
            "Frame: 473\n",
            "Frame: 474\n",
            "Frame: 475\n",
            "Frame: 476\n",
            "Frame: 477\n",
            "Frame: 478\n",
            "Frame: 479\n",
            "Frame: 480\n",
            "Frame: 481\n",
            "Frame: 482\n",
            "Frame: 483\n",
            "Frame: 484\n",
            "Frame: 485\n",
            "Frame: 486\n",
            "Frame: 487\n",
            "Frame: 488\n",
            "Frame: 489\n",
            "Frame: 490\n",
            "Frame: 491\n",
            "Frame: 492\n",
            "Frame: 493\n",
            "Frame: 494\n",
            "Frame: 495\n",
            "Frame: 496\n",
            "Frame: 497\n",
            "Frame: 498\n",
            "Frame: 499\n",
            "Frame: 500\n",
            "Frame: 501\n",
            "Frame: 502\n",
            "Frame: 503\n",
            "Frame: 504\n",
            "Frame: 505\n",
            "Frame: 506\n",
            "Frame: 507\n",
            "Frame: 508\n",
            "Frame: 509\n",
            "Frame: 510\n",
            "Frame: 511\n",
            "Frame: 512\n",
            "Frame: 513\n",
            "Frame: 514\n",
            "Frame: 515\n",
            "Frame: 516\n",
            "Frame: 517\n",
            "Frame: 518\n",
            "Frame: 519\n",
            "Frame: 520\n",
            "Frame: 521\n",
            "Frame: 522\n",
            "Frame: 523\n",
            "Frame: 524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/master_unipa/MOT17-09-DPM/MOT17-09-DPM-DETR07.txt', 'w') as f:\n",
        "    frame_count = 0\n",
        "    for detections_frame in detetions:\n",
        "        # indice del frame, detections e confidences\n",
        "        for i in range(len(detections_frame)):\n",
        "            print(f'{frame_count}, {detections_frame[i][0]}, {detections_frame[i][1]}', file=f)\n",
        "        frame_count += 1\n",
        "        # for conf, detect in zip(confidences, detections):\n",
        "        #     print(f'{detect},{conf}', file=f)"
      ],
      "metadata": {
        "id": "G8sl3z7ATvS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(detetions)"
      ],
      "metadata": {
        "id": "pFRFELLBmRAV",
        "outputId": "ddf58a33-627c-4f9d-b164-b524bbd4cace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_image_folder_only_detection(detections_preloaded, folder_path, frame_size=(640, 360), detection_interval=2, frame_limit_flag = False, limit=5):\n",
        "#     tracker = Tracker()\n",
        "#     frame_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "#     frame_count = 0\n",
        "\n",
        "#     detections_frame = []\n",
        "\n",
        "#     for frame_file in frame_files:\n",
        "#         if frame_limit_flag and frame_count > limit:\n",
        "#             break\n",
        "#         frame = Image.open(frame_file)\n",
        "\n",
        "#         if frame_count % detection_interval == 0:\n",
        "#             # confidences, detections = detect_pedestrians(im=frame, model=model)\n",
        "#             confidences, detections = detections_preloaded[frame_count]\n",
        "#         tracker.update_tracker(confidences, detections, frame, vgg16, theshold_det_track = 0.4, theshold_reid=0.4)\n",
        "\n",
        "#         actual_detections = [] # solo per print\n",
        "\n",
        "#         for track in tracker.trackers:\n",
        "#             if track['lost'] == 0:\n",
        "#                 x1, y1, x2, y2 = map(int, track['bbox'])\n",
        "#                 x = x1\n",
        "#                 y = y1\n",
        "#                 w = x2-x1\n",
        "#                 h = y2-y1\n",
        "#                 conf = track['conf']\n",
        "#                 # poi format_detection deve essere stampato in un file\n",
        "#                 format_detectetion = [frame_count, track['id'], x,y,w,h, track['conf'],-1,-1,-1]\n",
        "#                 print(format_detectetion)\n",
        "#                 actual_detections.append(format_detectetion) # solo per printing\n",
        "#                 detections_frame.append(format_detectetion)\n",
        "#         print(f'Frame: {frame_count}')\n",
        "#         # plot_image_w_detections(frame, actual_detections)\n",
        "#         frame_count += 1\n",
        "#     return detections_frame"
      ],
      "metadata": {
        "id": "7AfhPYDXagWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detected_to_file_2 = process_image_folder_only_detection()"
      ],
      "metadata": {
        "id": "0dnzqvWkazQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/master_unipa/risultati.txt', 'w') as f:\n",
        "#     for d in detected_to_file:\n",
        "#         frame,id,x,y,w,h,conf,_,_,_ = d\n",
        "#         print(f'{frame+1},{id},{x},{y},{w},{h},{conf},-1,-1,-1', file=f)"
      ],
      "metadata": {
        "id": "qgbtzkatASB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload\n",
        "path_data = '/content/drive/MyDrive/master_unipa/MOT17-13-DPM/MOT17-13-DPM-DETR06.txt'\n",
        "data_preloaded = []\n",
        "with open(path_data, 'r') as f:\n",
        "    for row in f:\n",
        "        frame, bboxes, confidences = row.split(',')\n",
        "        frame = int(frame)\n",
        "        x1, x2, y1, y2 = bboxes.strip('[] ').split()\n",
        "        x1 = float(x1)\n",
        "        x2 = float(x2)\n",
        "        y1 = float(y1)\n",
        "        y2 = float(y2)\n",
        "        conf = float(confidences.strip())\n",
        "        detection_frame = [frame,[x1,x2,y1,y2], conf]\n",
        "        data_preloaded.append(detection_frame)"
      ],
      "metadata": {
        "id": "0DHxFq57eQA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_preloaded"
      ],
      "metadata": {
        "id": "ejC42ZV7gA34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_detection = {}\n",
        "for data in data_preloaded:\n",
        "    if data[0] not in final_detection.keys():\n",
        "        final_detection[data[0]] = []\n",
        "    final_detection[data[0]].append([data[1], data[2]])"
      ],
      "metadata": {
        "id": "tPCP2MnPgLGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_detection)"
      ],
      "metadata": {
        "id": "IDq39mBkgvXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections_frame_1 = final_detection[1]\n",
        "detections_frame_1"
      ],
      "metadata": {
        "id": "XhcmW99lg2jb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}